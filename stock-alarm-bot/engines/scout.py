import requests
from bs4 import BeautifulSoup
from pykrx import stock
import time
import yfinance as yf
import pandas as pd
import config
from datetime import datetime, timedelta
import re

import pandas_datareader.data as pdr

class Scout:
    """
    [Scout V16.0]
    ì›¹ í¬ë¡¤ë§(BeautifulSoup)ê³¼ yfinanceë¥¼ ì‚¬ìš©í•˜ì—¬ ì›ì²œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì •ì°°ë³‘.
    """
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }

    def collect_data(self, sectors, macros):
        """
        í†µí•© ë°ì´í„° ìˆ˜ì§‘ (4ëŒ€ ì„ë¬´ ìˆ˜í–‰)
        """
        print(f"ğŸ•µï¸ Scout: ì •ì°° ì„ë¬´ ì‹œì‘... (Time: {datetime.now().strftime('%H:%M:%S')})")
        
        # [V16.8] SNR Calculation
        risk = self.get_risk_indices()
        pulse = self.calculate_pulse_score()
        
        try:
            vix_slope = float(risk.get("VIX_Slope", 0)) # dZ/dt (Acceleration of Impact)
            pulse_score = float(pulse.get("score", 0))
            
            # [Math Formula V16.10]
            # SNR = (Pulse * dZ/dt) / sigma_noise
            AVG_NOISE_INTENSITY = 1.0 # sigma_noise (Historical Average)
            
            # Pulseê°€ 0ì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ìµœì†Œ 0.5 ë³´ì • (Silent Crisis ë°©ì§€)
            adjusted_pulse = max(pulse_score, 0.5)
            
            # Calculate SNR
            snr = (adjusted_pulse * abs(vix_slope)) / AVG_NOISE_INTENSITY
            
            # ë°©í–¥ì„± ë³´ì •: Slopeê°€ ìŒìˆ˜ë©´ SNRë„ ìŒìˆ˜ë¡œ í‘œê¸° (Crisis Fading)
            if vix_slope < 0:
                snr = -snr
        except:
            snr = 0.0

        data = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "risk_indices": risk,
            "pulse_score": pulse,
            "snr": f"{snr:.2f}", # [V16.8] ì‹ í˜¸ ëŒ€ ì†ŒìŒë¹„
            "market_index": self.get_korea_market_index(),
            "macro": self.get_macro_data(macros),
            "players": self.get_players_data(),
            "policy_news": self.get_policy_news(),
            "micro": self.get_micro_data(sectors),
            "safe_haven_data": self.get_micro_data({"Defensive Assets": config.SAFE_HAVEN_TICKERS})
        }
        
        print(f"  - [SNR Analysis] Score: {snr:.2f} (Pulse: {pulse.get('score')}, Slope: {risk.get('VIX_Slope')})")
        print("âœ… Scout: ì •ì°° ì„ë¬´ ì™„ë£Œ.")
        return data

    def get_macro_data(self, macro_tickers):
        """
        ì„ë¬´ 1: ê±°ì‹œê²½ì œ ì •ì°° (ê¸ˆë¦¬, í™˜ìœ¨, ëŒ€ì²´ìì‚°, ë¨¸ë‹ˆë¬´ë¸Œ)
        """
        print("  - [1/4] ê±°ì‹œê²½ì œ ì§€í‘œ ìˆ˜ì§‘ ì¤‘...")
        result = {}

        # 1-1. ê¸€ë¡œë²Œ ì§€í‘œ (yfinance)
        for key, ticker_symbol in macro_tickers.items():
            try:
                ticker = yf.Ticker(ticker_symbol)
                hist = ticker.history(period="5d")
                if not hist.empty:
                    current = hist['Close'].iloc[-1]
                    prev = hist['Close'].iloc[-2]
                    change = ((current - prev) / prev) * 100
                    result[key] = f"{current:,.2f} ({change:+.2f}%)"
                else:
                    result[key] = "N/A"
            except Exception:
                result[key] = "Error"

        # 1-2. í•œêµ­ êµ­ê³ ì±„ ê¸ˆë¦¬ (ë„¤ì´ë²„ ê¸ˆìœµ í¬ë¡¤ë§) - yfinance ë°ì´í„° ë¶€ì¡± ë³´ì™„
        try:
            url = "https://finance.naver.com/marketindex/"
            res = requests.get(url, headers=self.headers)
            soup = BeautifulSoup(res.text, "html.parser")
            
            # (CSS ì„ íƒìëŠ” ë„¤ì´ë²„ ê¸ˆìœµ êµ¬ì¡°ì— ë§ì¶° ì¡°ì • í•„ìš”, ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œ ë¡œì§)
            # ì‹œì¥ì§€í‘œ ë¦¬ìŠ¤íŠ¸ ìˆœíšŒ ë¡œì§ì´ ë³µì¡í•˜ë¯€ë¡œ ê°„ë‹¨íˆ í™˜ìœ¨ ì²´í¬ë§Œ ì˜ˆì‹œë¡œ êµ¬í˜„í•˜ê±°ë‚˜
            # ì •í™•í•œ íŒŒì‹± ë¡œì§ì´ í•„ìš”. ì—¬ê¸°ì„œëŠ” 'ë¨¸ë‹ˆë¬´ë¸Œ'ì— ì§‘ì¤‘í•˜ê¸°ë¡œ í•¨.
            pass 
        except Exception as e:
            print(f"    âš ï¸ êµ­ê³ ì±„ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

        # 1-3. ë¨¸ë‹ˆë¬´ë¸Œ (ìœ ë™ì„±) - ì˜ˆíƒê¸ˆ, ì‹ ìš©ìœµì ë“±
        try:
            url = config.URLS["DEPOSIT"]
            res = requests.get(url, headers=self.headers)
            soup = BeautifulSoup(res.text, "html.parser")
            
            # ì˜ˆíƒê¸ˆ í…Œì´ë¸” íŒŒì‹± (ê°€ì •: class='type_2')
            # ì‹¤ì œ ë„¤ì´ë²„ ì¦ì‹œìê¸ˆë™í–¥ í˜ì´ì§€ êµ¬ì¡° ê¸°ë°˜
            table = soup.select_one("div.box_type_m > table.type_2")
            if table:
                rows = table.select("tr")
                # ì¼ë°˜ì ìœ¼ë¡œ ìƒë‹¨ í–‰ë“¤ì— ë°ì´í„° ìœ„ì¹˜
                # ì˜ˆ: ê³ ê°ì˜ˆíƒê¸ˆ(3ë²ˆì§¸ rows), ì‹ ìš©ìœµì(...), CMA(...)
                # ì •í™•í•œ í–‰ ì¸ë±ìŠ¤ëŠ” í˜ì´ì§€ ë³€ê²½ì— ì·¨ì•½í•˜ë¯€ë¡œ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ê¶Œì¥
                
                labels = ["ê³ ê°ì˜ˆíƒê¸ˆ", "ì‹ ìš©ìœµì", "CMA", "MMF"]
                for row in rows:
                    cols = row.select("td")
                    if len(cols) >= 2:
                        label = cols[0].get_text(strip=True)
                        value = cols[1].get_text(strip=True)
                        
                        for target in labels:
                            if target in label:
                                result[target] = value # ì½¤ë§ˆ í¬í•¨ ë¬¸ìì—´ ê·¸ëŒ€ë¡œ
        except Exception as e:
             print(f"    âš ï¸ ë¨¸ë‹ˆë¬´ë¸Œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
             

        return result

    def get_risk_indices(self):
        """
        [V16.5] Global Risk Indices (EPU, VIX Z-Score, GPR Proxy)
        """
        print("  - [Plus] ê¸€ë¡œë²Œ ë¦¬ìŠ¤í¬ ì§€í‘œ(EPU, VIX, GPR) ì •ë°€ ë¶„ì„ ì¤‘...")
        result = {"EPU": "N/A", "VIX": "N/A", "VIX_Z": "0.0", "GPR": "N/A"}
        
        # 1. US Economic Policy Uncertainty Index (FRED)
        try:
            start = datetime.now() - timedelta(days=60)
            end = datetime.now()
            epu_data = pdr.DataReader('USEPUINDXD', 'fred', start, end)
            if not epu_data.empty:
                result["EPU"] = f"{epu_data.iloc[-1].item():.2f}"
        except Exception as e:
            print(f"    âš ï¸ EPU ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

        # 2. VIX Z-Score (yfinance)
        try:
            vix = yf.Ticker("^VIX")
            # 30ì¼ ë°ì´í„° í™•ë³´ (Z-Score ê³„ì‚°ìš©)
            hist = vix.history(period="3mo") # ë„‰ë„‰íˆ 3ê°œì›”
            if len(hist) >= 30:
                 # Rolling Windowë¡œ êµ¬í˜„í•˜ë©´ ì¢‹ìœ¼ë‚˜, ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ ì „ì²´ê¸°ê°„ Mean/Std ì‚¬ìš©í•˜ë˜
                 # ìµœê·¼ ë°ì´í„° ë³€í™”ë¥¼ ë°˜ì˜
                recent = hist['Close']
                
                # Z-Score Calculation
                mean_vix = recent.mean()
                std_vix = recent.std()
                
                current_vix = recent.iloc[-1]
                prev_vix = recent.iloc[-2]
                prev2_vix = recent.iloc[-3]
                
                z_current = (current_vix - mean_vix) / std_vix if std_vix != 0 else 0
                z_prev = (prev_vix - mean_vix) / std_vix if std_vix != 0 else 0
                z_prev2 = (prev2_vix - mean_vix) / std_vix if std_vix != 0 else 0
                
                # Vp (Velocity)
                velocity_current = z_current - z_prev
                velocity_prev = z_prev - z_prev2
                
                # Ap (Acceleration)
                acceleration = velocity_current - velocity_prev
                
                result["VIX"] = f"{current_vix:.2f}"
                result["VIX_Z"] = f"{z_current:.2f}"
                result["VIX_Slope"] = f"{velocity_current:.2f}" # Vp
                result["VIX_Accel"] = f"{acceleration:.2f}" # Ap
        except Exception as e:
            print(f"    âš ï¸ VIX ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

        # 3. GPR Proxy (News Keyword Velocity)
        result["GPR_Proxy"] = self.get_gpr_proxy()
            
        return result

    def get_gpr_proxy(self):
        """
        [V16.5] ì •ì¹˜ ë¦¬ìŠ¤í¬ í”„ë¡ì‹œ (Risk Velocity)
        - íŠ¹ì • í‚¤ì›Œë“œ(ê³„ì—„, íƒ„í•µ ë“±)ì˜ ë‰´ìŠ¤ ì¶œí˜„ ë¹ˆë„ ì²´í¬
        """
        keywords = ['ê³„ì—„', 'ë‚´ë€', 'íƒ„í•µ', 'ICE', 'FBI ìˆ˜ìƒ‰', 'ë¶€ì •ì„ ê±°']
        hit_count = 0
        
        base_url = "https://search.naver.com/search.naver?where=news&sort=1&query="
        
        for kw in keywords:
            try:
                res = requests.get(base_url + kw, headers=self.headers, timeout=3)
                if res.status_code == 200:
                    soup = BeautifulSoup(res.text, "html.parser")
                    # ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œ ê°œìˆ˜ (ìµœëŒ€ 10ê°œ) ì¹´ìš´íŠ¸
                    # 'news_area'ëŠ” ê° ë‰´ìŠ¤ ì•„ì´í…œì˜ í´ë˜ìŠ¤
                    items = soup.select("div.news_area")
                    
                    # ê°„ë‹¨í•œ ë¡œì§: ìƒìœ„ 10ê°œ ì¤‘ '1ì‹œê°„ ì´ë‚´' ê¸°ì‚¬ê°€ ëª‡ ê°œì¸ì§€ ì²´í¬í•˜ë©´ ì¢‹ìœ¼ë‚˜
                    # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ ê²€ìƒ‰ ê²°ê³¼ ë…¸ì¶œ ì—¬ë¶€ë¡œ íŒë‹¨ (ê° í‚¤ì›Œë“œ ë‹¹ ìµœëŒ€ 1ì )
                    if items:
                        hit_count += 1
            except:
                continue
                
        # Risk Level Logic
        risk_level = "Stable"
        if hit_count >= 3:
            risk_level = "CRITICAL (Political Shock)"
        elif hit_count >= 1:
            risk_level = "Warning"
            
        return {"score": hit_count, "status": risk_level}

    def calculate_pulse_score(self):
        """
        [V16.6] Pulse Layer: ë‰´ìŠ¤ ì„¼í‹°ë¨¼íŠ¸ ì ìˆ˜í™”
        - ìœ„ê¸° ë‹¨ì–´(2.0) vs ì¼ë°˜ ë‹¨ì–´(0.5) ê°€ì¤‘ì¹˜ í•©ì‚°
        """
        print("  - [Plus] Pulse Score (News Sentiment) ê³„ì‚° ì¤‘...")
        total_score = 0.0
        details = []
        
        keywords = config.CRISIS_KEYWORDS if hasattr(config, 'CRISIS_KEYWORDS') else {}
        base_url = "https://search.naver.com/search.naver?where=news&sort=1&query="
        
        for kw, weight in keywords.items():
            try:
                # ë‹¨ìˆœ ê²€ìƒ‰ ë…¸ì¶œ ì—¬ë¶€ í™•ì¸ (ë¹ ë¥¸ ì†ë„ë¥¼ ìœ„í•´ timeout ì§§ê²Œ)
                res = requests.get(base_url + kw, headers=self.headers, timeout=2)
                if res.status_code == 200:
                    soup = BeautifulSoup(res.text, "html.parser")
                    if soup.select("div.news_area"):
                        total_score += weight
                        details.append(kw)
            except:
                 continue
                 
        return {"score": total_score, "matches": ", ".join(details[:5])} # ìƒìœ„ 5ê°œë§Œ í‘œê¸°

    # -------------------------------------------------------------------------
    # ê¸°ì¡´ ë©”ì†Œë“œë“¤ (get_macro_data ë“±) ìœ ì§€...
    def get_korea_market_index(self):
        """
        [ê³µê³µë°ì´í„°í¬í„¸] êµ­ë‚´ ì§€ìˆ˜ ì‹œì„¸ (KOSPI, KOSDAQ)
        """
        print("  - [Plus] êµ­ë‚´ ì§€ìˆ˜(KOSPI/KOSDAQ) í™•ì¸ ì¤‘...")
        data = {"KOSPI": {"price": "0", "change": "0"}, "KOSDAQ": {"price": "0", "change": "0"}}
        
        api_key = config.DATA_GO_KR_API_KEY
        if not api_key:
            return data

        base_url = "https://apis.data.go.kr/1160100/service/GetMarketIndexInfoService/getStockMarketIndex"
        # ìµœê·¼ ì˜ì—…ì¼ ë°ì´í„° í™•ë³´ë¥¼ ìœ„í•´ ì˜¤ëŠ˜~3ì¼ ì „ê¹Œì§€ ì¡°íšŒ (ìµœê·¼ ë°ì´í„° íšë“ìš©)
        # today = datetime.now().strftime("%Y%m%d") # Unused variable removed
        
        # basDtëŠ” í•„ìˆ˜. ì£¼ë§ ê³ ë ¤í•˜ì—¬ ìµœê·¼ í‰ì¼ë¡œ ì„¤ì •
        # ë‹¨, API íŠ¹ì„±ìƒ ì •í™•í•œ ë‚ ì§œë¥¼ ëª¨ë¥´ë©´ ë£¨í”„ë¥¼ ëŒê±°ë‚˜ ë²”ìœ„ë¥¼ ì¤˜ì•¼ í•˜ëŠ”ë°, 
        # numOfRows=10 & resultType=jsonìœ¼ë¡œ ìµœê·¼ ë°ì´í„°ê°€ ìƒìœ„ì— ì˜¤ëŠ”ì§€ í™•ì¸ í•„ìš”.
        # ê³µê³µë°ì´í„°í¬í„¸ì€ ë³´í†µ basDtë¥¼ ì§€ì •í•´ì•¼ í•¨. ì–´ì œ ë‚ ì§œë¡œ ì‹œë„.
        
        target_date = (datetime.now() - timedelta(days=1)).strftime("%Y%m%d")
        if datetime.now().weekday() == 0: # ì›”ìš”ì¼ì´ë©´ ê¸ˆìš”ì¼ ë°ì´í„°
            target_date = (datetime.now() - timedelta(days=3)).strftime("%Y%m%d")
        elif datetime.now().weekday() == 6: # ì¼ìš”ì¼ì´ë©´ ê¸ˆìš”ì¼
            target_date = (datetime.now() - timedelta(days=2)).strftime("%Y%m%d")

        params = {
            "serviceKey": api_key,
            "resultType": "json",
            "numOfRows": "10",
            "basDt": target_date
        }
        
        try:
            res = requests.get(base_url, params=params, timeout=5)
            if res.status_code == 200:
                try:
                    items = res.json().get("response", {}).get("body", {}).get("items", {}).get("item", [])
                    for item in items:
                        name = item.get("idxNm")
                        price = item.get("clpr") # ì¢…ê°€
                        flt = item.get("fltRt") # ë“±ë½ë¥ 
                        
                        if name == "ì½”ìŠ¤í”¼":
                            data["KOSPI"] = {"price": price, "change": flt, "date": item.get("basDt")}
                        elif name == "ì½”ìŠ¤ë‹¥":
                            data["KOSDAQ"] = {"price": price, "change": flt, "date": item.get("basDt")}
                except:
                    pass
            elif res.status_code == 403:
                print("    âš ï¸ ê³µê³µë°ì´í„°í¬í„¸ ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ (í™œìš©ì‹ ì²­ í•„ìš”)")
        except Exception as e:
            print(f"    âš ï¸ ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            
        return data

    # ìƒë‹¨ import ì¶”ê°€ëŠ” ë³„ë„ ì²˜ë¦¬í•˜ì§€ ì•Šê³ , ì—¬ê¸°ì„œ ë©”ì†Œë“œ êµì²´ë§Œ ìˆ˜í–‰
    # (importëŠ” multi-replace ë˜ëŠ” ë³„ë„ í˜¸ì¶œë¡œ ì²˜ë¦¬í•´ì•¼ í•˜ë¯€ë¡œ, ì´ ë„êµ¬ í˜¸ì¶œì—ì„œëŠ” ë©”ì†Œë“œ ë³¸ë¬¸ë§Œ êµì²´í•˜ê³ 
    #  import ë¬¸ì€ íŒŒì¼ ìƒë‹¨ì— ì¶”ê°€í•´ì•¼ í•¨. í•˜ì§€ë§Œ replace_file_contentëŠ” í•œ ë²ˆì— í•˜ë‚˜ì˜ ë¸”ë¡ë§Œ ìˆ˜ì • ê°€ëŠ¥.
    #  ë”°ë¼ì„œ ì—¬ê¸°ì„œëŠ” ë©”ì†Œë“œë¥¼ êµì²´í•˜ê³ , ë‹¤ìŒ í˜¸ì¶œì—ì„œ importë¥¼ ì¶”ê°€í•˜ê² ìŒ.)
    
    def get_players_data(self):
        """
        [ìˆ˜ê¸‰ ë°ì´í„° ìˆ˜ì§‘]
        ë„¤ì´ë²„ í¬ë¡¤ë§ ì°¨ë‹¨ ì‹œ ëŒ€ì•ˆ: PyKRX (í•œêµ­ê±°ë˜ì†Œ ë°ì´í„°) ì‚¬ìš©
        """
        try:
            today = datetime.now()
            today_str = today.strftime("%Y%m%d")
            
            # ìš”ì¼ ê³„ì‚° (0:ì›” ~ 6:ì¼)
            idx = today.weekday()
            
            # ë‚ ì§œ ë²”ìœ„ ì„¤ì • (YYYYMMDD í¬ë§·)
            # 1. ì´ë²ˆì£¼ (ì›”ìš”ì¼ ~ ì˜¤ëŠ˜)
            this_week_start_dt = today - timedelta(days=idx)
            this_week_start = this_week_start_dt.strftime("%Y%m%d")
            this_week_end = today_str
            
            # 2. ì§€ë‚œì£¼ (ì§€ë‚œì£¼ ì›” ~ ì§€ë‚œì£¼ ê¸ˆ)
            last_week_end_dt = this_week_start_dt - timedelta(days=3) # ì§€ë‚œì£¼ ê¸ˆìš”ì¼ (ì›”-3ì¼)
            last_week_start_dt = last_week_end_dt - timedelta(days=4) # ì§€ë‚œì£¼ ì›”ìš”ì¼ (ê¸ˆ-4ì¼)
            
            last_week_start = last_week_start_dt.strftime("%Y%m%d")
            last_week_end = last_week_end_dt.strftime("%Y%m%d")

            # KRXì—ì„œ ê¸°ê°„ë³„ íˆ¬ìì ìˆœë§¤ìˆ˜ ë°ì´í„° ì¡°íšŒ (ì½”ìŠ¤í”¼ ì „ì²´)
            # IP ì°¨ë‹¨ ë“±ìœ¼ë¡œ ë°ì´í„°ê°€ ë¹„ì–´ìˆì„ ê²½ìš° ëŒ€ë¹„
            try:
                from pykrx import stock
                df_this = stock.get_market_trading_value_by_date(this_week_start, this_week_end, "KOSPI")
                df_last = stock.get_market_trading_value_by_date(last_week_start, last_week_end, "KOSPI")
            except Exception as e:
                print(f"    âš ï¸ PyKRX ì ‘ì† ì‹¤íŒ¨: {e}")
                df_this = pd.DataFrame()
                df_last = pd.DataFrame()

            # ë°ì´í„°ê°€ ë¹„ì–´ìˆì„ ê²½ìš° (ì¥ ì‹œì‘ ì „ ë˜ëŠ” ì°¨ë‹¨ë¨) 0ìœ¼ë¡œ ì²˜ë¦¬
            if df_this.empty:
                this_foreign = 0
                this_inst = 0
                this_ant = 0
            else:
                try:
                    # ì–µ ì› ë‹¨ìœ„ë¡œ ë³€í™˜
                    this_foreign = int(df_this['ì™¸êµ­ì¸'].sum() / 100000000)
                    this_inst = int(df_this['ê¸°ê´€í•©ê³„'].sum() / 100000000)
                    this_ant = int(df_this['ê°œì¸'].sum() / 100000000)
                except:
                    this_foreign = 0; this_inst = 0; this_ant = 0

            if df_last.empty:
                last_foreign = 0
                last_inst = 0
                last_ant = 0
            else:
                try:
                    last_foreign = int(df_last['ì™¸êµ­ì¸'].sum() / 100000000)
                    last_inst = int(df_last['ê¸°ê´€í•©ê³„'].sum() / 100000000)
                    last_ant = int(df_last['ê°œì¸'].sum() / 100000000)
                except:
                    last_foreign = 0; last_inst = 0; last_ant = 0

            return {
                "this_week": {'foreign': this_foreign, 'inst': this_inst, 'ant': this_ant},
                "last_week": {'foreign': last_foreign, 'inst': last_inst, 'ant': last_ant},
                "d_day": idx + 1
            }

        except Exception as e:
            print(f"âš ï¸ KRX ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {
                "this_week": {'foreign': 0, 'inst': 0, 'ant': 0},
                "last_week": {'foreign': 0, 'inst': 0, 'ant': 0},
                "d_day": 0,
                "error": str(e)
            }

    def get_policy_news(self):
        """
        ì„ë¬´ 3: ì •ì±… ë° ì§€ì •í•™ ë‰´ìŠ¤ ê°ì²­
        """
        print("  - [3/4] ë‰´ìŠ¤ í‚¤ì›Œë“œ ê°ì²­ ì¤‘...")
        news_report = {}
        
        keywords = config.NEWS_KEYWORDS if hasattr(config, 'NEWS_KEYWORDS') else []
        base_url = "https://search.naver.com/search.naver?where=news&sort=1&query="
        
        for keyword in keywords:
            try:
                url = base_url + keyword
                res = requests.get(url, headers=self.headers)
                soup = BeautifulSoup(res.text, "html.parser")
                
                # ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ì²« ë²ˆì§¸ ì•„ì´í…œ
                news_item = soup.select_one("div.news_area")
                if news_item:
                    title_tag = news_item.select_one("a.news_tit")
                    if title_tag:
                        title = title_tag.get_text()
                        link = title_tag['href']
                        news_report[keyword] = {"title": title, "link": link}
            except Exception:
                continue
                
        return news_report

    def get_micro_data(self, sectors):
        """
        ì„ë¬´ 4: ì„¹í„° ì •ë°€ íƒ€ê²© (ë²„í•/ë©ê±° ì§€í‘œ í¬í•¨)
        """
        print("  - [4/4] ì„¹í„°ë³„ ì •ë°€ ë¶„ì„ ì¤‘...")
        micro_data = {}

        for sector, tickers in sectors.items():
            sector_data = {}
            for ticker_code, name in tickers.items():
                try:
                    t = yf.Ticker(ticker_code)
                    info = t.info
                    
                    price = info.get('currentPrice', 0)
                    prev_close = info.get('previousClose', price)
                    change_rate = ((price - prev_close) / prev_close) * 100 if prev_close else 0
                    
                    # í•µì‹¬ ì§€í‘œ (Buffett/Munger style)
                    gpm = info.get('grossMargins', 0) * 100 # GPM
                    opm = info.get('operatingMargins', 0) * 100 # OPM
                    roe = info.get('returnOnEquity', 0) * 100 # ROE
                    
                    sector_data[name] = {
                        "price": f"{price:,.0f}" if "KS" in ticker_code or "KQ" in ticker_code else f"${price:.2f}",
                        "change": f"{change_rate:+.2f}%",
                        "GPM": f"{gpm:.1f}%",
                        "OPM": f"{opm:.1f}%",
                        "ROE": f"{roe:.1f}%"
                    }
                except Exception as e:
                    # yfinance info ëˆ„ë½ ì‹œ ëŒ€ë¹„ ë‹¨ìˆœ ê³„ì‚° ì‹œë„
                    # (ì—¬ê¸°ì„œëŠ” ì—ëŸ¬ ë¡œê¹… í›„ íŒ¨ìŠ¤)
                    # print(f"    âš ï¸ {name} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    sector_data[name] = "Data Unavailable"
            
            micro_data[sector] = sector_data
            
        return micro_data
