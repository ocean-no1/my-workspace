import requests
from bs4 import BeautifulSoup
import yfinance as yf
import pandas as pd
import config
from datetime import datetime, timedelta
import re

class Scout:
    """
    [Scout V16.0]
    ì›¹ í¬ë¡¤ë§(BeautifulSoup)ê³¼ yfinanceë¥¼ ì‚¬ìš©í•˜ì—¬ ì›ì²œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì •ì°°ë³‘.
    """
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }

    def collect_data(self, sectors, macros):
        """
        í†µí•© ë°ì´í„° ìˆ˜ì§‘ (4ëŒ€ ì„ë¬´ ìˆ˜í–‰)
        """
        print(f"ğŸ•µï¸ Scout: ì •ì°° ì„ë¬´ ì‹œì‘... (Time: {datetime.now().strftime('%H:%M:%S')})")
        
        data = {
            "macro": self.get_macro_data(macros),
            "players": self.get_players_data(),
            "policy_news": self.get_policy_news(),
            "micro": self.get_micro_data(sectors)
        }
        
        print("âœ… Scout: ì •ì°° ì„ë¬´ ì™„ë£Œ.")
        return data

    def get_macro_data(self, macro_tickers):
        """
        ì„ë¬´ 1: ê±°ì‹œê²½ì œ ì •ì°° (ê¸ˆë¦¬, í™˜ìœ¨, ëŒ€ì²´ìì‚°, ë¨¸ë‹ˆë¬´ë¸Œ)
        """
        print("  - [1/4] ê±°ì‹œê²½ì œ ì§€í‘œ ìˆ˜ì§‘ ì¤‘...")
        result = {}

        # 1-1. ê¸€ë¡œë²Œ ì§€í‘œ (yfinance)
        for key, ticker_symbol in macro_tickers.items():
            try:
                ticker = yf.Ticker(ticker_symbol)
                hist = ticker.history(period="5d")
                if not hist.empty:
                    current = hist['Close'].iloc[-1]
                    prev = hist['Close'].iloc[-2]
                    change = ((current - prev) / prev) * 100
                    result[key] = f"{current:,.2f} ({change:+.2f}%)"
                else:
                    result[key] = "N/A"
            except Exception:
                result[key] = "Error"

        # 1-2. í•œêµ­ êµ­ê³ ì±„ ê¸ˆë¦¬ (ë„¤ì´ë²„ ê¸ˆìœµ í¬ë¡¤ë§) - yfinance ë°ì´í„° ë¶€ì¡± ë³´ì™„
        try:
            url = "https://finance.naver.com/marketindex/"
            res = requests.get(url, headers=self.headers)
            soup = BeautifulSoup(res.text, "html.parser")
            
            # (CSS ì„ íƒìëŠ” ë„¤ì´ë²„ ê¸ˆìœµ êµ¬ì¡°ì— ë§ì¶° ì¡°ì • í•„ìš”, ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œ ë¡œì§)
            # ì‹œì¥ì§€í‘œ ë¦¬ìŠ¤íŠ¸ ìˆœíšŒ ë¡œì§ì´ ë³µì¡í•˜ë¯€ë¡œ ê°„ë‹¨íˆ í™˜ìœ¨ ì²´í¬ë§Œ ì˜ˆì‹œë¡œ êµ¬í˜„í•˜ê±°ë‚˜
            # ì •í™•í•œ íŒŒì‹± ë¡œì§ì´ í•„ìš”. ì—¬ê¸°ì„œëŠ” 'ë¨¸ë‹ˆë¬´ë¸Œ'ì— ì§‘ì¤‘í•˜ê¸°ë¡œ í•¨.
            pass 
        except Exception as e:
            print(f"    âš ï¸ êµ­ê³ ì±„ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

        # 1-3. ë¨¸ë‹ˆë¬´ë¸Œ (ìœ ë™ì„±) - ì˜ˆíƒê¸ˆ, ì‹ ìš©ìœµì ë“±
        try:
            url = config.URLS["DEPOSIT"]
            res = requests.get(url, headers=self.headers)
            soup = BeautifulSoup(res.text, "html.parser")
            
            # ì˜ˆíƒê¸ˆ í…Œì´ë¸” íŒŒì‹± (ê°€ì •: class='type_2')
            # ì‹¤ì œ ë„¤ì´ë²„ ì¦ì‹œìê¸ˆë™í–¥ í˜ì´ì§€ êµ¬ì¡° ê¸°ë°˜
            table = soup.select_one("div.box_type_m > table.type_2")
            if table:
                rows = table.select("tr")
                # ì¼ë°˜ì ìœ¼ë¡œ ìƒë‹¨ í–‰ë“¤ì— ë°ì´í„° ìœ„ì¹˜
                # ì˜ˆ: ê³ ê°ì˜ˆíƒê¸ˆ(3ë²ˆì§¸ rows), ì‹ ìš©ìœµì(...), CMA(...)
                # ì •í™•í•œ í–‰ ì¸ë±ìŠ¤ëŠ” í˜ì´ì§€ ë³€ê²½ì— ì·¨ì•½í•˜ë¯€ë¡œ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ê¶Œì¥
                
                labels = ["ê³ ê°ì˜ˆíƒê¸ˆ", "ì‹ ìš©ìœµì", "CMA", "MMF"]
                for row in rows:
                    cols = row.select("td")
                    if len(cols) >= 2:
                        label = cols[0].get_text(strip=True)
                        value = cols[1].get_text(strip=True)
                        
                        for target in labels:
                            if target in label:
                                result[target] = value # ì½¤ë§ˆ í¬í•¨ ë¬¸ìì—´ ê·¸ëŒ€ë¡œ
        except Exception as e:
             print(f"    âš ï¸ ë¨¸ë‹ˆë¬´ë¸Œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
             
        return result

    def get_players_data(self):
        """
        ì„ë¬´ 2: ìˆ˜ê¸‰ ì „íˆ¬ í˜„í™© (íˆ¬ììë³„ ë§¤ë§¤ë™í–¥ + í”„ë¡œê·¸ë¨, ì£¼ê°„ vs ì§€ë‚œì£¼ ë¹„êµ)
        """
        print("  - [2/4] ìˆ˜ê¸‰ ë°ì´í„° ì •ë°€ íƒ€ê²© ì¤‘...")
        result = {}
        
        # 2-1. íˆ¬ììë³„ ë§¤ë§¤ë™í–¥
        try:
            url = config.URLS["INVESTOR_TREND"]
            res = requests.get(url, headers=self.headers)
            
            # StringIOë¡œ ê°ì‹¸ê¸° (Pandas FutureWarning í•´ê²°)
            from io import StringIO
            html_io = StringIO(res.text)
            
            # í…Œì´ë¸” ì¶”ì¶œ (class="type_1"ì´ ì—†ì„ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ ìœ ì—°í•˜ê²Œ)
            # "ë‚ ì§œ" í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ í…Œì´ë¸”ì„ ì°¾ë„ë¡ ë³€ê²½
            df_list = pd.read_html(html_io, match="ë‚ ì§œ", flavor='bs4')
            
            if df_list:
                df = df_list[0]
                # ì»¬ëŸ¼: ë‚ ì§œ, ê°œì¸, ì™¸êµ­ì¸, ê¸°ê´€ê³„, ...
                # ë°ì´í„° ì •ì œ (NaN ì œê±°)
                df = df.dropna()
                
                # ë‚ ì§œ ê¸°ì¤€ ì´ë²ˆì£¼/ì§€ë‚œì£¼ ë‚˜ëˆ„ê¸°
                today = datetime.now().date()
                start_of_this_week = today - timedelta(days=today.weekday()) # ì›”ìš”ì¼
                start_of_last_week = start_of_this_week - timedelta(days=7)
                end_of_last_week = start_of_this_week - timedelta(days=1) # ì§€ë‚œì£¼ ì¼ìš”ì¼(ë˜ëŠ” ê¸ˆìš”ì¼)
                
                # ë‚ ì§œ í¬ë§· í™•ì¸ (ì˜ˆ: '24.01.30')
                # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ìƒìœ„ 5ê°œ(ì´ë²ˆì£¼), ê·¸ ë‹¤ìŒ 5ê°œ(ì§€ë‚œì£¼) ë³´ëŠ” ë¡œì§ìœ¼ë¡œ ëŒ€ì²´ ê°€ëŠ¥í•˜ì§€ë§Œ,
                # ì •ì„ëŒ€ë¡œ ë‚ ì§œ íŒŒì‹± ì‹œë„
                
                current_week_sum = {"ê°œì¸": 0, "ì™¸êµ­ì¸": 0, "ê¸°ê´€": 0}
                last_week_sum = {"ê°œì¸": 0, "ì™¸êµ­ì¸": 0, "ê¸°ê´€": 0}
                
                for _, row in df.iterrows():
                    try:
                        date_str = str(row.iloc[0]) # ë‚ ì§œ
                        # ì—°ë„ ì¶”ê°€ í•„ìš”í•  ìˆ˜ ìˆìŒ (ë„¤ì´ë²„ëŠ” yy.mm.dd)
                        if len(date_str) == 8: # 24.01.01
                            dt = datetime.strptime(date_str, "%y.%m.%d").date()
                            
                            # ìˆ˜ì¹˜ ë³€í™˜ (ë¬¸ìì—´ -> ì •ìˆ˜)
                            def parse_money(val):
                                if isinstance(val, (int, float)): return val
                                return int(str(val).replace(",", ""))
                                
                            personal = parse_money(row.iloc[1])
                            foreigner = parse_money(row.iloc[2])
                            institution = parse_money(row.iloc[3])
                            
                            if start_of_this_week <= dt <= today:
                                current_week_sum["ê°œì¸"] += personal
                                current_week_sum["ì™¸êµ­ì¸"] += foreigner
                                current_week_sum["ê¸°ê´€"] += institution
                            elif start_of_last_week <= dt <= end_of_last_week:
                                last_week_sum["ê°œì¸"] += personal
                                last_week_sum["ì™¸êµ­ì¸"] += foreigner
                                last_week_sum["ê¸°ê´€"] += institution
                    except:
                        continue
                        
                result["this_week"] = current_week_sum
                result["last_week"] = last_week_sum
                
        except Exception as e:
            print(f"    âš ï¸ ë§¤ë§¤ë™í–¥ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            result["error"] = str(e)

        # 2-2. í”„ë¡œê·¸ë¨ ë§¤ë§¤ (ë¹„ì°¨ìµ)
        try:
            url = config.URLS["PROGRAM_TRADE"]
            res = requests.get(url, headers=self.headers)
            soup = BeautifulSoup(res.text, "html.parser")
            
            # ë‹¹ì¼ í”„ë¡œê·¸ë¨ ë§¤ë§¤ ë™í–¥ íŒŒì‹±
            # (ìƒë‹¨ ìš”ì•½ ë°•ìŠ¤ ë˜ëŠ” í…Œì´ë¸”ì—ì„œ 'ë¹„ì°¨ìµ' ìˆœë§¤ìˆ˜ ì°¾ê¸°)
            # dl.blind êµ¬ì¡° ë“±ì„ ì‚¬ìš©í•˜ê±°ë‚˜ í…Œì´ë¸” ì ‘ê·¼
            # ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ ìƒëµëœ ë¡œì§ì„ ë³´ì™„ -> í…Œì´ë¸”ì—ì„œ ìµœìƒë‹¨ í–‰ ì¶”ì¶œ
            pass 
        except:
             pass

        return result

    def get_policy_news(self):
        """
        ì„ë¬´ 3: ì •ì±… ë° ì§€ì •í•™ ë‰´ìŠ¤ ê°ì²­
        """
        print("  - [3/4] ë‰´ìŠ¤ í‚¤ì›Œë“œ ê°ì²­ ì¤‘...")
        news_report = {}
        
        keywords = config.NEWS_KEYWORDS if hasattr(config, 'NEWS_KEYWORDS') else []
        base_url = "https://search.naver.com/search.naver?where=news&sort=1&query="
        
        for keyword in keywords:
            try:
                url = base_url + keyword
                res = requests.get(url, headers=self.headers)
                soup = BeautifulSoup(res.text, "html.parser")
                
                # ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ì²« ë²ˆì§¸ ì•„ì´í…œ
                news_item = soup.select_one("div.news_area")
                if news_item:
                    title_tag = news_item.select_one("a.news_tit")
                    if title_tag:
                        title = title_tag.get_text()
                        link = title_tag['href']
                        news_report[keyword] = {"title": title, "link": link}
            except Exception:
                continue
                
        return news_report

    def get_micro_data(self, sectors):
        """
        ì„ë¬´ 4: ì„¹í„° ì •ë°€ íƒ€ê²© (ë²„í•/ë©ê±° ì§€í‘œ í¬í•¨)
        """
        print("  - [4/4] ì„¹í„°ë³„ ì •ë°€ ë¶„ì„ ì¤‘...")
        micro_data = {}

        for sector, tickers in sectors.items():
            sector_data = {}
            for ticker_code, name in tickers.items():
                try:
                    t = yf.Ticker(ticker_code)
                    info = t.info
                    
                    price = info.get('currentPrice', 0)
                    prev_close = info.get('previousClose', price)
                    change_rate = ((price - prev_close) / prev_close) * 100 if prev_close else 0
                    
                    # í•µì‹¬ ì§€í‘œ (Buffett/Munger style)
                    gpm = info.get('grossMargins', 0) * 100 # GPM
                    opm = info.get('operatingMargins', 0) * 100 # OPM
                    roe = info.get('returnOnEquity', 0) * 100 # ROE
                    
                    sector_data[name] = {
                        "price": f"{price:,.0f}" if "KS" in ticker_code or "KQ" in ticker_code else f"${price:.2f}",
                        "change": f"{change_rate:+.2f}%",
                        "GPM": f"{gpm:.1f}%",
                        "OPM": f"{opm:.1f}%",
                        "ROE": f"{roe:.1f}%"
                    }
                except Exception as e:
                    # yfinance info ëˆ„ë½ ì‹œ ëŒ€ë¹„ ë‹¨ìˆœ ê³„ì‚° ì‹œë„
                    # (ì—¬ê¸°ì„œëŠ” ì—ëŸ¬ ë¡œê¹… í›„ íŒ¨ìŠ¤)
                    # print(f"    âš ï¸ {name} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    sector_data[name] = "Data Unavailable"
            
            micro_data[sector] = sector_data
            
        return micro_data
